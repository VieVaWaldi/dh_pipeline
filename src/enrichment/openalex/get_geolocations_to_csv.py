import math
import os
from datetime import datetime

import pandas as pd
from dotenv import load_dotenv

from core.etl.data_loader.utils.create_db_session import create_db_session
from datamodels.digicher.entities import Institutions
from enrichment.openalex.search_geolocations import search_geolocation


def get_distance_in_meters(point1, point2):
    """
    @ Generated by Claude
    Calculate the great-circle distance between two points on Earth using the Haversine formula.

    Parameters:
    point1 (list): [latitude, longitude] of first point
    point2 (list): [latitude, longitude] of second point

    Returns:
    float: Distance between points in meters
    """
    R = 6371000  # Earth's radius in meters

    lat1, lng1 = point1
    lat2, lng2 = point2

    d_lat = (lat2 - lat1) * math.pi / 180
    d_lng = (lng2 - lng1) * math.pi / 180

    a = math.sin(d_lat / 2) * math.sin(d_lat / 2) + math.cos(
        lat1 * math.pi / 180
    ) * math.cos(lat2 * math.pi / 180) * math.sin(d_lng / 2) * math.sin(d_lng / 2)

    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))
    distance = R * c

    return distance


load_dotenv()

BATCH_SIZE = 50
OFFSET = 1600

columns = [
    "institution_id",
    "institution_name",
    "search_result_name",
    "institution_geolocation",
    "dist (m)",
    "source",
]


timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
csv_filename = f"cordis_2_openalex_geo_{timestamp}.csv"
file_exists = os.path.isfile(csv_filename)

session_factory = create_db_session()
with session_factory() as session:
    print(f"Starting the process at {timestamp}")
    print(f"Results will be saved to {csv_filename}")

    keep_going = True
    while keep_going:
        print(f"Processing batch with OFFSET = {OFFSET}")
        rows = (
            session.query(Institutions)
            .filter(Institutions.address_geolocation.is_(None))
            .limit(BATCH_SIZE)
            .offset(OFFSET)
            .all()
        )

        batch_df = pd.DataFrame(columns=columns)

        for institution in rows:
            search_result = search_geolocation(institution)

            if institution.address_geolocation:
                dist = get_distance_in_meters(
                    institution.address_geolocation,
                    [
                        float(search_result["latitude"]),
                        float(search_result["longitude"]),
                    ],
                )
            else:
                dist = ""

            if dist and float(dist) < 150:
                continue

            batch_df.loc[len(batch_df)] = [
                institution.id,
                institution.name,
                search_result["name"],
                (
                    f"{search_result['latitude']}, {search_result['longitude']}"
                    if search_result["latitude"] is not None
                    else ""
                ),
                round(dist, 0) if dist else "",
                search_result["source"],
            ]

        if not batch_df.empty:
            batch_df.to_csv(
                csv_filename,
                mode="a",
                header=not file_exists,  # Only write header if file doesn't exist
                index=False,
                sep=";",
            )
            file_exists = True  # Set to true for subsequent batches
            print(f"Appended {len(batch_df)} rows to {csv_filename}")
        else:
            print("No matching results in this batch")

        if len(rows) < BATCH_SIZE:
            keep_going = False
            print("Final batch processed, ending process")
        else:
            OFFSET += BATCH_SIZE

    print(f"Process completed. Results saved to {csv_filename}")
